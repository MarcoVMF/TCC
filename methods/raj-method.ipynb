{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:31.403217Z",
     "iopub.status.busy": "2025-05-04T14:28:31.402440Z",
     "iopub.status.idle": "2025-05-04T14:28:38.795727Z",
     "shell.execute_reply": "2025-05-04T14:28:38.794891Z",
     "shell.execute_reply.started": "2025-05-04T14:28:31.403187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:42.485317Z",
     "iopub.status.busy": "2025-05-04T14:28:42.484942Z",
     "iopub.status.idle": "2025-05-04T14:28:42.547813Z",
     "shell.execute_reply": "2025-05-04T14:28:42.547108Z",
     "shell.execute_reply.started": "2025-05-04T14:28:42.485294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of BiHPF and PRNU filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:42.670988Z",
     "iopub.status.busy": "2025-05-04T14:28:42.670710Z",
     "iopub.status.idle": "2025-05-04T14:28:42.675324Z",
     "shell.execute_reply": "2025-05-04T14:28:42.674665Z",
     "shell.execute_reply.started": "2025-05-04T14:28:42.670968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bilateral_high_pass_filter(image_path, d=9, sigma_color=75, sigma_space=75):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # img should be a grayscale or single-channel image\n",
    "    smooth = cv2.bilateralFilter(img, d, sigma_color, sigma_space)\n",
    "    high_pass = cv2.subtract(img, smooth)\n",
    "    return high_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:44.002226Z",
     "iopub.status.busy": "2025-05-04T14:28:44.001840Z",
     "iopub.status.idle": "2025-05-04T14:28:44.009686Z",
     "shell.execute_reply": "2025-05-04T14:28:44.008852Z",
     "shell.execute_reply.started": "2025-05-04T14:28:44.002195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_prnu_sprectrum(image_path, gaussian_kernel_size=3, gaussian_sigma=1.0, rms_window_size=3):\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "\n",
    "    img_ycbcr = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    img_y = img_ycbcr[:, :, 0].astype(np.float32)\n",
    "\n",
    "    img_y /= 255.\n",
    "\n",
    "    img_blur = cv2.GaussianBlur(img_y, (gaussian_kernel_size, gaussian_kernel_size), gaussian_sigma)\n",
    "\n",
    "    residual = img_y - img_blur\n",
    "\n",
    "    squared = residual ** 2\n",
    "    mean_squared = uniform_filter(squared, size=rms_window_size)\n",
    "    rms_residual = np.sqrt(mean_squared)\n",
    "\n",
    "    mean_rms = np.mean(rms_residual)\n",
    "    prnu_spectrum = rms_residual / (mean_rms + 1e-8)  # evita divisão por zero\n",
    "\n",
    "    return prnu_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:44.146742Z",
     "iopub.status.busy": "2025-05-04T14:28:44.146381Z",
     "iopub.status.idle": "2025-05-04T14:28:44.155877Z",
     "shell.execute_reply": "2025-05-04T14:28:44.155202Z",
     "shell.execute_reply.started": "2025-05-04T14:28:44.146711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dir = \"/kaggle/input/real-and-fake-images/dataset/train\"\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, device='cuda', transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label in ['fake_images', 'real_images']:\n",
    "            label_dir = os.path.join(self.image_dir, label)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(1 if label == 'fake_images' else 0)\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.image_dir))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        BiHPF_img = bilateral_high_pass_filter(img_path)\n",
    "        PRNU_img = extract_prnu_sprectrum(img_path)\n",
    "    \n",
    "        feature_map = np.stack([BiHPF_img, PRNU_img], axis=-1)  \n",
    "    \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            feature_map = self.transform(feature_map)\n",
    "    \n",
    "        return feature_map, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the path embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:45.802748Z",
     "iopub.status.busy": "2025-05-04T14:28:45.802135Z",
     "iopub.status.idle": "2025-05-04T14:28:45.810230Z",
     "shell.execute_reply": "2025-05-04T14:28:45.809465Z",
     "shell.execute_reply.started": "2025-05-04T14:28:45.802719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=2, embed_dim=768, use_cls_token=True):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = in_channels\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.use_cls_token = use_cls_token\n",
    "\n",
    "        self.projection = nn.Linear(in_channels * patch_size * patch_size, embed_dim)\n",
    "        if use_cls_token:\n",
    "            self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "            self.num_patches += 1\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, self.num_patches, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size and W == self.img_size, f\"Esperado {self.img_size}×{self.img_size}, mas recebeu {H}×{W}\"\n",
    "        assert C == self.in_channels\n",
    "\n",
    "        patches = x.unfold(2, self.patch_size, self.patch_size) \\\n",
    "                   .unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(B, C, -1, self.patch_size, self.patch_size)\n",
    "        patches = patches.permute(0, 2, 1, 3, 4)\n",
    "        patches = patches.flatten(2)\n",
    "\n",
    "        patch_embeddings = self.projection(patches)  \n",
    "\n",
    "        if self.use_cls_token:\n",
    "            cls_tokens = self.cls_token.expand(B, -1, -1) \n",
    "            patch_embeddings = torch.cat([cls_tokens, patch_embeddings], dim=1)  \n",
    "\n",
    "\n",
    "        patch_embeddings = patch_embeddings + self.pos_embedding\n",
    "\n",
    "        return patch_embeddings  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:46.022980Z",
     "iopub.status.busy": "2025-05-04T14:28:46.022377Z",
     "iopub.status.idle": "2025-05-04T14:28:46.030820Z",
     "shell.execute_reply": "2025-05-04T14:28:46.030090Z",
     "shell.execute_reply.started": "2025-05-04T14:28:46.022956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class DualHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim deve ser divisível por num_heads\"\n",
    "\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, E = x.shape\n",
    "\n",
    "        x_norm = self.norm1(x)\n",
    "\n",
    "        Q = self.q_proj(x_norm)\n",
    "        K = self.k_proj(x_norm)\n",
    "        V = self.v_proj(x_norm)\n",
    "\n",
    "        Q = Q.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)  \n",
    "        K = K.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        attn_output = torch.matmul(attn_probs, V)\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, N, E)\n",
    "\n",
    "        out = self.out_proj(attn_output)\n",
    "        out = self.norm2(out + x)  \n",
    "\n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:47.993135Z",
     "iopub.status.busy": "2025-05-04T14:28:47.992863Z",
     "iopub.status.idle": "2025-05-04T14:28:47.997850Z",
     "shell.execute_reply": "2025-05-04T14:28:47.997076Z",
     "shell.execute_reply.started": "2025-05-04T14:28:47.993116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = x[:, 0, :] \n",
    "        logits = self.mlp(cls_token)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:48.186536Z",
     "iopub.status.busy": "2025-05-04T14:28:48.185713Z",
     "iopub.status.idle": "2025-05-04T14:28:48.191376Z",
     "shell.execute_reply": "2025-05-04T14:28:48.190599Z",
     "shell.execute_reply.started": "2025-05-04T14:28:48.186508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GANDetectionModel(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels=2, embed_dim=embed_dim)\n",
    "        self.attn_block = DualHeadSelfAttention(embed_dim=embed_dim)\n",
    "        self.classifier = Classifier(embed_dim=embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, H, W, 2]\n",
    "        x = self.patch_embed(x)         \n",
    "        x = self.attn_block(x)           \n",
    "        logits = self.classifier(x)      \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:49.724247Z",
     "iopub.status.busy": "2025-05-04T14:28:49.723564Z",
     "iopub.status.idle": "2025-05-04T14:28:49.728854Z",
     "shell.execute_reply": "2025-05-04T14:28:49.728192Z",
     "shell.execute_reply.started": "2025-05-04T14:28:49.724225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToPILImage(),\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:52.140365Z",
     "iopub.status.busy": "2025-05-04T14:28:52.139677Z",
     "iopub.status.idle": "2025-05-04T14:28:52.357264Z",
     "shell.execute_reply": "2025-05-04T14:28:52.356493Z",
     "shell.execute_reply.started": "2025-05-04T14:28:52.140342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(image_dir=image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:54.260271Z",
     "iopub.status.busy": "2025-05-04T14:28:54.259725Z",
     "iopub.status.idle": "2025-05-04T14:28:54.321348Z",
     "shell.execute_reply": "2025-05-04T14:28:54.320828Z",
     "shell.execute_reply.started": "2025-05-04T14:28:54.260249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = GANDetectionModel()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:28:56.111783Z",
     "iopub.status.busy": "2025-05-04T14:28:56.111161Z",
     "iopub.status.idle": "2025-05-04T14:29:01.863849Z",
     "shell.execute_reply": "2025-05-04T14:29:01.863042Z",
     "shell.execute_reply.started": "2025-05-04T14:28:56.111759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Loss: 0.725012481212616\n",
      "[2/100] Loss: 0.2652965188026428\n",
      "[3/100] Loss: 0.11526736617088318\n",
      "[4/100] Loss: 0.082882821559906\n",
      "[5/100] Loss: 0.04764764755964279\n",
      "[6/100] Loss: 0.019114738330245018\n",
      "[7/100] Loss: 0.023878809064626694\n",
      "[8/100] Loss: 0.016685351729393005\n",
      "[9/100] Loss: 0.007581563666462898\n",
      "[10/100] Loss: 0.008214038796722889\n",
      "[11/100] Loss: 0.004565594717860222\n",
      "[12/100] Loss: 0.004019990097731352\n",
      "[13/100] Loss: 0.006741341203451157\n",
      "[14/100] Loss: 0.0050885374657809734\n",
      "[15/100] Loss: 0.002784386742860079\n",
      "[16/100] Loss: 0.0023856949992477894\n",
      "[17/100] Loss: 0.002550278790295124\n",
      "[18/100] Loss: 0.0029604299925267696\n",
      "[19/100] Loss: 0.0031932496931403875\n",
      "[20/100] Loss: 0.003320696298032999\n",
      "[21/100] Loss: 0.0018338726367801428\n",
      "[22/100] Loss: 0.003983508795499802\n",
      "[23/100] Loss: 0.0023817517794668674\n",
      "[24/100] Loss: 0.0018352956976741552\n",
      "[25/100] Loss: 0.0026498246006667614\n",
      "[26/100] Loss: 0.0020438856445252895\n",
      "[27/100] Loss: 0.0022020828910171986\n",
      "[28/100] Loss: 0.0014692828990519047\n",
      "[29/100] Loss: 0.0013714430388063192\n",
      "[30/100] Loss: 0.0014003920368850231\n",
      "[31/100] Loss: 0.000976691022515297\n",
      "[32/100] Loss: 0.0010316402185708284\n",
      "[33/100] Loss: 0.0010239188559353352\n",
      "[34/100] Loss: 0.0011364659294486046\n",
      "[35/100] Loss: 0.0009710206650197506\n",
      "[36/100] Loss: 0.000662952777929604\n",
      "[37/100] Loss: 0.0011370186693966389\n",
      "[38/100] Loss: 0.0009017328266054392\n",
      "[39/100] Loss: 0.000717891613021493\n",
      "[40/100] Loss: 0.0007690633647143841\n",
      "[41/100] Loss: 0.0007520873914472759\n",
      "[42/100] Loss: 0.0009530064417049289\n",
      "[43/100] Loss: 0.0005153284291736782\n",
      "[44/100] Loss: 0.000496024964377284\n",
      "[45/100] Loss: 0.0006016597035340965\n",
      "[46/100] Loss: 0.0006013965466991067\n",
      "[47/100] Loss: 0.0006790456245653331\n",
      "[48/100] Loss: 0.0005621392047032714\n",
      "[49/100] Loss: 0.0004927488043904305\n",
      "[50/100] Loss: 0.0007769717485643923\n",
      "[51/100] Loss: 0.0004993232432752848\n",
      "[52/100] Loss: 0.000918331672437489\n",
      "[53/100] Loss: 0.0013383018085733056\n",
      "[54/100] Loss: 0.0005879473173990846\n",
      "[55/100] Loss: 0.0006255742628127337\n",
      "[56/100] Loss: 0.0008209464722312987\n",
      "[57/100] Loss: 0.000810341676697135\n",
      "[58/100] Loss: 0.0003733458579517901\n",
      "[59/100] Loss: 0.00045787813724018633\n",
      "[60/100] Loss: 0.00033173043630085886\n",
      "[61/100] Loss: 0.00044304950279183686\n",
      "[62/100] Loss: 0.0006069986848160625\n",
      "[63/100] Loss: 0.000515681691467762\n",
      "[64/100] Loss: 0.001020905445329845\n",
      "[65/100] Loss: 0.0004351793904788792\n",
      "[66/100] Loss: 0.00023237205459736288\n",
      "[67/100] Loss: 0.00036341973464004695\n",
      "[68/100] Loss: 0.0007756205159239471\n",
      "[69/100] Loss: 0.0004944952670484781\n",
      "[70/100] Loss: 0.0005240357131697237\n",
      "[71/100] Loss: 0.00027680088533088565\n",
      "[72/100] Loss: 0.0005757600301876664\n",
      "[73/100] Loss: 0.0006064102053642273\n",
      "[74/100] Loss: 0.0005996551481075585\n",
      "[75/100] Loss: 0.0005585214239545166\n",
      "[76/100] Loss: 0.00031396205304190516\n",
      "[77/100] Loss: 0.00026329903630539775\n",
      "[78/100] Loss: 0.00023956960649229586\n",
      "[79/100] Loss: 0.0004221406998112798\n",
      "[80/100] Loss: 0.0003674890613183379\n",
      "[81/100] Loss: 0.00023374153533950448\n",
      "[82/100] Loss: 0.0002899270330090076\n",
      "[83/100] Loss: 0.0002019999665208161\n",
      "[84/100] Loss: 0.00021033830125816166\n",
      "[85/100] Loss: 0.00033398051164112985\n",
      "[86/100] Loss: 0.00030635748407803476\n",
      "[87/100] Loss: 0.00022722556605003774\n",
      "[88/100] Loss: 0.00016203316044993699\n",
      "[89/100] Loss: 0.00016089348355308175\n",
      "[90/100] Loss: 0.00031416930141858757\n",
      "[91/100] Loss: 0.0003031441301573068\n",
      "[92/100] Loss: 0.0003095008141826838\n",
      "[93/100] Loss: 0.0001644177973503247\n",
      "[94/100] Loss: 0.00019719332340173423\n",
      "[95/100] Loss: 0.00021987827494740486\n",
      "[96/100] Loss: 0.00021152292902115732\n",
      "[97/100] Loss: 0.00012720312224701047\n",
      "[98/100] Loss: 0.00013804857735522091\n",
      "[99/100] Loss: 0.0002951287606265396\n",
      "[100/100] Loss: 0.0003715740458574146\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)   \n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        out = model(images)          \n",
    "        loss = criterion(out.squeeze(), labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"[{epoch}/{epochs}] Loss: {epoch_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:31:20.489020Z",
     "iopub.status.busy": "2025-05-04T14:31:20.488685Z",
     "iopub.status.idle": "2025-05-04T14:31:20.555624Z",
     "shell.execute_reply": "2025-05-04T14:31:20.555069Z",
     "shell.execute_reply.started": "2025-05-04T14:31:20.488999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_image_dir = \"/kaggle/input/real-and-fake-images/dataset/validation\"\n",
    "val_dataset = CustomDataset(image_dir=val_image_dir, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:32:13.302597Z",
     "iopub.status.busy": "2025-05-04T14:32:13.301897Z",
     "iopub.status.idle": "2025-05-04T14:32:13.404659Z",
     "shell.execute_reply": "2025-05-04T14:32:13.404099Z",
     "shell.execute_reply.started": "2025-05-04T14:32:13.302574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)    \n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        logits = model(images)        \n",
    "        loss   = criterion(logits.squeeze(), labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        probs     = torch.sigmoid(logits).squeeze()\n",
    "        preds     = (probs > 0.5).long()\n",
    "        correct  += (preds == labels.long()).sum().item()\n",
    "        total    += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:35:26.626116Z",
     "iopub.status.busy": "2025-05-04T14:35:26.625536Z",
     "iopub.status.idle": "2025-05-04T14:35:26.630107Z",
     "shell.execute_reply": "2025-05-04T14:35:26.629424Z",
     "shell.execute_reply.started": "2025-05-04T14:35:26.626095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.00017810953431762755\n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Loss: {avg_loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:36:25.664661Z",
     "iopub.status.busy": "2025-05-04T14:36:25.664076Z",
     "iopub.status.idle": "2025-05-04T14:36:25.695433Z",
     "shell.execute_reply": "2025-05-04T14:36:25.694847Z",
     "shell.execute_reply.started": "2025-05-04T14:36:25.664638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7078326,
     "sourceId": 11316276,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
